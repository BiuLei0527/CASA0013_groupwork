---
bibliography: bio.bib
csl: harvard-cite-them-right.csl
title: Group Name's Group Project
execute:
  echo: false
  freeze: true
format:
  html:
    code-copy: true
    code-link: true
    toc: true
    toc-title: On this page
    toc-depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
  pdf:
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
    mainfont: Spectral
    sansfont: Roboto Flex
    monofont: InputMonoCondensed
    papersize: a4
    geometry:
      - top=25mm
      - left=40mm
      - right=30mm
      - bottom=25mm
      - heightrounded
    toc: false
    number-sections: false
    colorlinks: true
    highlight-style: github
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.16.4
  kernelspec:
    display_name: Python (base)
    language: python
    name: base
---

```{python}
%matplotlib inline
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt  
import seaborn as sns
import geopandas as gpd
import requests
from requests import get
```

```{python}
host = 'https://orca.casa.ucl.ac.uk'
path = '~jreades/data'
file = '20240614-London-listings.csv.gz'
url  = f'{host}/{path}/{file}'

if os.path.exists(file):
  df = pd.read_csv(file, compression='gzip', low_memory=False)
else: 
  df = pd.read_csv(url, compression='gzip', low_memory=False)
  df.to_csv(file, compression='gzip', index=False)
```

## 1. Who collected the InsideAirbnb data?

::: {.10/11/2024}

( 2 points; Answer due Week 7 )

::: 

Inside Airbnb, founded in 2015, its founder Murray Cox began conceiving the project in 2014 and started collecting Airbnb data and aggregating it into an interactive web-based interface [@PuckLo]. After years of development, the website has collaborators, new members, and advisory board to help with project development, data collection etc.

## 2. Why did they collect the InsideAirbnb data?

::: {.11/11/2024}

( 4 points; Answer due Week 7 )

:::

This project was inspired by the DIVAS summer camp project in 2014. Afterwards, Murray considered the reasons for displacement and began to reflect on ‘how Airbnb is used in my community.' [@PuckLo, @insideairbnb_about].

More important reasons come from the social concerns and issues raised by Airbnb. Murray, criticising the sharing economy, argues that it ‘threatens affordable housing and exacerbates gentrification' [@Katz], where individuals transfer underutilised resources to others, such as Uber and Airbnb [@alsudais]. In 2015, Murray and Tom Slee discovered that many listings had disappeared from Airbnb data of New York, which was a misleading depiction of their business and went against Airbnb's original vision and commitment to the community.

It is based on these inspirations and facts that Inside Airbnb has been working hard to collect data about Airbnb worldwide and stand up for the development of community housing and the rights of tenants and single room landlords.

```{python}
print(f"Data frame is {df.shape[0]:,} x {df.shape[1]:,}")
```

```{python}
ax = df.host_listings_count.plot.hist(bins=50);
ax.set_xlim([0,500]);
```

## 3. How was the InsideAirbnb data collected?  

::: {.12/11/2024}

( 5 points; Answer due Week 8 )

:::

Inside Airbnb provides large open dataset that collects data from the official public listings on the Airbnb website, including detailed descriptions, property types, and user reviews. The data is collected through python scripts, which are sourced from Github and other online resource [@alsudais], each listing page on the website.

The data collection can be divided into the following stages: First, finding all public listings on the Airbnb website as much as possible. Second, accessing each page through the script to collect information such as the ID of the listing, the type of home, the time it was published, the number of reviews, and the location. Finally, aggregating the data and verifying it with the number of data published by Airbnb. They use the number of reviews as the number of visits to the listing for they lack internal data [@CoxSlee].

They state that no private information is used in the data collection process and that the names of the listings are compiled by comparing the geographical coordinates of the listings with the city-to-community definitions. Also in a later development, 50% of the comment rate was converted to an estimated booking and an average length of stay was assigned to each city [@insideairbnb_data_assumptions].

## 4. How does the method of collection impact the completeness and/or accuracy of the InsideAirbnb data set's representation of the process it seeks to study, and what wider issues does this raise?

::: {.15/11/2024}

( 11 points; Answer due Week 9 )

:::

It is obvious that the main data source of IA (Inside Airbnb) lacks accuracy, as it is obtained by directly scraping data collected by Airbnb itself from its website [@CoxSlee]. In addition, other data sources for the IA dataset are also unreliable, which are related to the data collection methods of Python scripts. Specifically, Python scripts are likely to generate IA datasets by copying scripts that lack responsible maintenance on any websites [@insideairbnb_behind], with GitHub being an example [@alsudais]. Moreover, the automated generation of code for data collection services for IA datasets may encounter issues such as ignoring list types and making incorrect links [@alsudais], which can lead to problems include duplicating data collection, data position errors, and data omissions. For example, automated code may simplify or truncate some property review fields.

Overall, the IA dataset covers a wide range of data, such as various housing types and different landlord characteristics. This is beneficial for the process of data research. However, unreliable data sources and automatically generated codes affect the research results of IA. In addition, due to the setting of monthly updates [@alsudais], the dataset of IA is not updated in real time, which brings the problem that the existing dataset cannot represent the real data. As a result, the IA dataset can only representbthe process it wishes to study to some extent. Specifically, only when the research scope, problem definition, time constraints, and data processing methods are clearly defined, can the IA dataset effectively reflect analytical research.

The formation of IA datasets due to inaccurate collection methods has resulted in more serious consequences, including impacts on research results, public trust towards the internet, and political and financial advice. For reseachers who use inaccurate IA datasets for research, the reproducibility of their research results will be doubted. Additionally, as the errors in the IA dataset increase, the public's trust in online information will decrease accordingly. Furthermore, as an important reference, if the IA dataset lacks accuracy, relevant political and economic decisions may be misled.

## 5. What ethical considerations does the use of the InsideAirbnb data raise? 

::: {.18/11/2024}

( 18 points; Answer due {{< var assess.group-date >}} )

:::

We analyze its ethical issues through four stages: purpose of data use，data collection, data storage, use and impact of analysis results.

1. Purpose of Data Use:
The transparency of Inside Airbnb itself: Inside Airbnb's mission statement is to protect the city from short-term rentals [@insideairbnb_about]. When using Inside Airbnb data for research, there is a need to consider the alignment of the research objectives with its mission. This may diminish the objectivity of the data and lead to biased results in the analysis.

2. Data Collection:
Data source: Inside Airbnb says it’s not endorsed by Airbnb [@insideairbnb_data_assumptions]. Airbnb expressly states that it prohibits using automated means to access or collect data from the Airbnb Platform. But whether Inside Airbnb collects its data through Python scripts may involve legal and ethical controversies that should be considered.

The accuracy of Inside Airbnb data: Inside Airbnb says it is not responsible for the accuracy of the information [@insideairbnb_data_assumptions]. It just provides snapshot data at a point in time and anonymizes listing location information. These can affect the timeliness and accuracy of the analysis.

Data privacy and security: Being able to access or collect data does not mean that it is ethical to use that data [@boyd2014networked]. Although Inside Airbnb claims in its disclaimer that the data is safe and full-protected, it is risky that it involves sensitive content such as names, photos, locations and reviews, which may indirectly expose individuals' privacy, and trigger ethical judging of data collection and privacy security.

3. Data storage
Fairness of data access: Inside Airbnb provides the most recent 12 months of data for free, but access to archived data is subject to review or even payment [@insideairbnb_data_assumptions], which may be a hindrance to researchers or organizations with limited resources.

Security Risks: Long-term storage of archived data may be subject to security risks associated with data aging, storage media damage, or technology updates. Without regular security audits and backup management, data security may be jeopardized.

4. Use and Impacts of Analysis Results:
A risk of misuse: The analysis results derived from public data could be taken out of context to support unfair policies or biased conclusions.
Unfair business competition: conclusions and analyses based on Inside Airbnb data could be exploited by competitors in the same industry to harm Airbnb or landlords engaged in lawful operations.

Challenges of public distrust: deepening public distrust and doubt about the sharing economy, inducing people to overlook the economic benefits that platforms like Airbnb may bring to certain landlords and tenants.

## 6. With reference to the InsideAirbnb data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and Listing types suggest about the nature of Airbnb lets in London? 

::: {.duedate}

( 15 points; Answer due {{< var assess.group-date >}} )

:::

## 7. Drawing on your previous answers, and supporting your response with evidence (e.g. figures, maps, and statistical analysis/models), how *could* the InsideAirbnb data set be used to inform the regulation of Short-Term Lets (STL) in London? 

::: {.duedate}

( 45 points; Answer due {{< var assess.group-date >}} )

:::

## Sustainable Authorship Tools

Your QMD file should automatically download your BibTeX file. We will then re-run the QMD file to generate the output successfully.

Written in Markdown and generated from [Quarto](https://quarto.org/). Fonts used: [Spectral](https://fonts.google.com/specimen/Spectral) (mainfont), [Roboto](https://fonts.google.com/specimen/Roboto) (<span style="font-family:Sans-Serif;">sansfont</span>) and [JetBrains Mono](https://fonts.google.com/specimen/JetBrains%20Mono) (`monofont`). 

## References


## 6. With reference to the InsideAirbnb data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and Listing types suggest about the nature of Airbnb lets in London? 

::: {.duedate}

( 15 points; Answer due {{< var assess.group-date >}} )

:::

Firstly, an analysis of the types of Airbnb listings in London is presented in order to summarise their main characteristics.

```{python}
listings_type = df.loc[:, ['room_type','latitude', 'longitude']]
counts = listings_type['room_type'].value_counts().to_dict()
orders = ['Entire home/apt', 'Private room', 'Shared room', 'Hotel room']
plt.figure(figsize=(8,6))
ax=sns.countplot(data=listings_type, x='room_type', order=orders, palette="deep")
for c in ax.containers:
    labels = [counts[l] for l in counts.keys()]
    ax.bar_label(c, label=labels, fontsize=10)
plt.title('Counts of Different Room Type in London')
plt.show()
```

```{python}
gdf_bnb = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude, crs='epsg:4326'))
url = 'https://github.com/jreades/i2p/blob/master/data/src/Boroughs.gpkg?raw=true'
file_name='Boroughs.gpkg'
response=requests.get(url)
with open (file_name, 'wb') as file:
    file.write(response.content)
boroughs=gpd.read_file(file_name)
```

```{python}
bnb_gdf = gdf_bnb.to_crs(boroughs.crs)
fig, ax=plt.subplots(figsize=(12, 8))
boroughs.plot(ax=ax, facecolor='lightgrey', edgecolor='black', alpha=0.7)
types=bnb_gdf['room_type'].unique().tolist()
colors=['#A23B72','#6CB4EE','#3D315B','#F2C641'] 
markers=['*','s','^','+']
for t in types:
    subset=bnb_gdf[bnb_gdf['room_type']==t]
    subset.plot(ax=ax, markersize=2, color=colors[types.index(t)], label=t, marker=markers[types.index(t)])
ax.legend(title='Room Type', markerscale=5)
ax.set_title("Airbnb Listings by Room Type")
plt.show()
```

```{python}
import plotly.graph_objects as go
boroughs_json=boroughs.__geo_interface__
fig = go.Figure()
fig.add_trace(go.Choroplethmapbox(geojson=boroughs_json, locations=boroughs['NAME'], colorscale="Cividis", marker=dict(opacity=0.75), showscale=False))
types=bnb_gdf['room_type'].unique().tolist()
colors=['#A23B72','#6CB4EE','#3D315B','#F2C641'] 

for t in types:
    subset=bnb_gdf[bnb_gdf['room_type']==t]
    fig.add_trace(go.Scattermapbox(lon=subset['longitude'],lat=subset['latitude'], mode='markers', marker=dict(size=5, color=colors[types.index(t)]), name=t))
fig.update_layout(title="Airbnb Listings by Room Type", legend=dict(title="Room Type"), mapbox=dict(style="open-street-map", center=dict(lat=bnb_gdf['latitude'].mean(), lon=bnb_gdf['longitude'].mean()),zoom=15))
fig.show()
```

```{python}
bnb_borough=gpd.sjoin(bnb_gdf, boroughs, how="inner", predicate="within")
bnb_counts=bnb_borough.groupby("NAME").size().reset_index()
bnb_counts=bnb_counts.rename(columns={0:"counts"})
bnb_merge=pd.merge(boroughs, bnb_counts, on="NAME")
f, ax=plt.subplots(figsize=(12,8))
ax=bnb_merge.plot(ax=ax, column="counts", cmap="Greens", edgecolor="black", legend=True)
plt.title("Airbnb Listings Distribution in Boroughs")
plt.show()
```

```{python}
response_rate_mean = df["host_response_rate"].dropna().mean()
acceptance_rate_mean = df["host_acceptance_rate"].dropna().mean()
print(f"The average acceptance rate of host in London is {acceptance_rate_mean}, and average response rate is {response_rate_mean}")
response_time = df["host_response_time"].dropna().value_counts()
print(f"{response_time['within an hour']}Landlord replies within an hour, {response_time['within a few hours']}landlord replies within a few hours, {response_time['within a day']}landlord replies within a day, {response_time['a few days or more']}landlord replies only after a few days or more")
```

```{python}
property = df.property_type.value_counts()
sorted = property.sort_values(ascending=False).reset_index()
```

```{python}
import nltk
import re
from nltk.tokenize import word_tokenize, sent_tokenize 
from nltk.tokenize.toktok import ToktokTokenizer
from sklearn.feature_extraction.text import TfidfVectorizer 
from sklearn.feature_extraction.text import CountVectorizer 
from sklearn.decomposition import LatentDirichletAllocation
from nltk import ngrams, FreqDist
from wordcloud import WordCloud
```

```{python}
description = df.loc[:, 'description']
pattern = re.compile(r'<.*?>')
description_na = description.fillna(' ').values
description_norm = []
for t in description_na:
    clean_text = re.sub(pattern, ' ', t)
    description_norm.append(clean_text)
tfvectorizer = TfidfVectorizer(use_idf=True, ngram_range=(1,3), max_df=0.75, min_df=0.01, stop_words='english')
tfdescription = tfvectorizer.fit_transform(description_norm)
tfdif_des = pd.DataFrame(data=tfdescription.toarray(),columns=tfvectorizer.get_feature_names_out())
tfdif_des.sum().sort_values(ascending=False)
f,ax = plt.subplots(1,1,figsize=(8, 8))
plt.gcf().set_dpi(200)
cloud_des=WordCloud(background_color='white',max_words=120).generate_from_frequencies(tfdif_des.sum())
ax.imshow(cloud_des) 
ax.axis("off")
```

```{python}
identity = df["host_identity_verified"].dropna().value_counts()
profile = df["host_has_profile_pic"].dropna().value_counts()
superhost = df["host_is_superhost"].dropna().value_counts()
f, ax = plt.subplots(figsize=(8,6))
identity.plot(position=0, ax=ax, kind="bar", color="grey", width=0.1, label='Counts of T/F Identity Verified')
profile.plot(position=1, ax=ax, kind="bar", color="skyblue", width=0.1, label='Counts of T/F Have Profiles')
superhost.plot(position=2, ax=ax, kind="bar", color="green", width=0.1, label='Counts of T/F Superhost')
ax.set_ylabel("Counts")
ax.set_xlabel("T/F Identity Verified/Have Profiles/Superhost")
ax.set_xticklabels(['TRUE', 'FALSE'], rotation=45)
plt.legend()
plt.show()
```


